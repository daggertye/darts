{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _data_transforms_cifar10():\n",
    "  CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n",
    "  CIFAR_STD = [0.24703233, 0.24348505, 0.26158768]\n",
    "\n",
    "  train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
    "  ])\n",
    "\n",
    "  valid_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
    "    ])\n",
    "  return train_transform, valid_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform, valid_transform = _data_transforms_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         ...,\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373]],\n",
       "\n",
       "        [[-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         ...,\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373]],\n",
       "\n",
       "        [[-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         ...,\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373],\n",
       "         [-0.9373, -0.9373, -0.9373,  ..., -0.9373, -0.9373, -0.9373]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])(PIL.Image.fromarray(8 * np.ones((32, 32, 3)).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as dset\n",
    "train_data = dset.CIFAR10(root='../data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9892, -1.9892, -1.9892,  ...,  0.1063,  0.1539,  0.0745],\n",
       "         [-1.9892, -1.9892, -1.9892,  ..., -0.0684, -0.1001, -0.3541],\n",
       "         [-1.9892, -1.9892, -1.9892,  ..., -0.0842, -0.2906, -0.5922],\n",
       "         ...,\n",
       "         [-1.9892, -1.9892, -1.9892,  ..., -1.9892, -1.9892, -1.9892],\n",
       "         [-1.9892, -1.9892, -1.9892,  ..., -1.9892, -1.9892, -1.9892],\n",
       "         [-1.9892, -1.9892, -1.9892,  ..., -1.9892, -1.9892, -1.9892]],\n",
       "\n",
       "        [[-1.9802, -1.9802, -1.9802,  ..., -0.5307, -0.4824, -0.5307],\n",
       "         [-1.9802, -1.9802, -1.9802,  ..., -0.7079, -0.7079, -0.9011],\n",
       "         [-1.9802, -1.9802, -1.9802,  ..., -0.6918, -0.8850, -1.1105],\n",
       "         ...,\n",
       "         [-1.9802, -1.9802, -1.9802,  ..., -1.9802, -1.9802, -1.9802],\n",
       "         [-1.9802, -1.9802, -1.9802,  ..., -1.9802, -1.9802, -1.9802],\n",
       "         [-1.9802, -1.9802, -1.9802,  ..., -1.9802, -1.9802, -1.9802]],\n",
       "\n",
       "        [[-1.7070, -1.7070, -1.7070,  ..., -0.9724, -0.9424, -0.9574],\n",
       "         [-1.7070, -1.7070, -1.7070,  ..., -1.0924, -1.1073, -1.2273],\n",
       "         [-1.7070, -1.7070, -1.7070,  ..., -1.0324, -1.1973, -1.3472],\n",
       "         ...,\n",
       "         [-1.7070, -1.7070, -1.7070,  ..., -1.7070, -1.7070, -1.7070],\n",
       "         [-1.7070, -1.7070, -1.7070,  ..., -1.7070, -1.7070, -1.7070],\n",
       "         [-1.7070, -1.7070, -1.7070,  ..., -1.7070, -1.7070, -1.7070]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transform(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_data[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4], [0, 2, 5, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor(2, 4).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x)):\n",
    "    for j in range(x.size(1)):\n",
    "        if bool(x[i][j] == torch.min(x[i])):\n",
    "            y[i][j] = 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x.numpy(), 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [0, 2, 5, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
